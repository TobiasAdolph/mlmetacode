Threads to validity:
* borders of disciplines are fuzzy (in real world)

Evaluation procedure:
* For each model m in models:
    * for each config in configspace(m):
        * for each sampletype in (min, mean, median, max):
            * train model on train (+val)
            * predict on test
            * calculate confusion matrix for test
            * Calculate total accuracy (min) and average accuracy (mean, median, max)
* For each sampletype in (min, mean, median, max):
    * select n-best combinations(m, config), plot and discuss them.
* Check:
    * AUC
    * models = mlp, knn, svm, ?
