TODO:
    dtype int32
    decode_error replace
    
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import SelectKBest

selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))
selector.fit(x_train, train_labels)

activation sigmoid(1) softmax(2)
multi-layer perceptron model
    # Arguments
        layers: int, number of `Dense` layers in the model.
        units: int, output dimension of the layers.
        dropout_rate: float, percentage of input to drop at Dropout layers.
        input_shape: tuple, shape of input to the model.
        num_classes: int, number of output classes.

learning_rate
epochs
batch_size
layers
units

loss function
    binary_crossentropy 2
    sparse_categorical_crossentropy (multi)

optimizer = tf.keras.optimizers.Adam(lr=learning_rate)
# alternatives for acc?
model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])

history = model.fit(
            x_train,
            train_labels,
            epochs=epochs,
            callbacks=callbacks,
            validation_data=(x_val, val_labels),
            verbose=2,  # Logs once per epoch.
            batch_size=batch_size)

https://developers.google.com/machine-learning/guides/text-classification/step-5
sepCNN


